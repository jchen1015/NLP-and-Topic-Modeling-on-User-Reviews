{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/judychen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/judychen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "b'Skipping line 8704: expected 15 fields, saw 22\\nSkipping line 16933: expected 15 fields, saw 22\\nSkipping line 23726: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 85637: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 132136: expected 15 fields, saw 22\\nSkipping line 158070: expected 15 fields, saw 22\\nSkipping line 166007: expected 15 fields, saw 22\\nSkipping line 171877: expected 15 fields, saw 22\\nSkipping line 177756: expected 15 fields, saw 22\\nSkipping line 181773: expected 15 fields, saw 22\\nSkipping line 191085: expected 15 fields, saw 22\\nSkipping line 196273: expected 15 fields, saw 22\\nSkipping line 196331: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 197000: expected 15 fields, saw 22\\nSkipping line 197011: expected 15 fields, saw 22\\nSkipping line 197432: expected 15 fields, saw 22\\nSkipping line 208016: expected 15 fields, saw 22\\nSkipping line 214110: expected 15 fields, saw 22\\nSkipping line 244328: expected 15 fields, saw 22\\nSkipping line 248519: expected 15 fields, saw 22\\nSkipping line 254936: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 272057: expected 15 fields, saw 22\\nSkipping line 293214: expected 15 fields, saw 22\\nSkipping line 310507: expected 15 fields, saw 22\\nSkipping line 312306: expected 15 fields, saw 22\\nSkipping line 316296: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 336028: expected 15 fields, saw 22\\nSkipping line 344885: expected 15 fields, saw 22\\nSkipping line 352551: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 408773: expected 15 fields, saw 22\\nSkipping line 434535: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 581593: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 652409: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "# Import data.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df = pd.read_csv('watch_reviews.tsv', sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>3653882</td>\n",
       "      <td>R3O9SGZBVQBV76</td>\n",
       "      <td>B00FALQ1ZC</td>\n",
       "      <td>937001370</td>\n",
       "      <td>Invicta Women's 15150 \"Angel\" 18k Yellow Gold ...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Absolutely love this watch! Get compliments al...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>14661224</td>\n",
       "      <td>RKH8BNC3L5DLF</td>\n",
       "      <td>B00D3RGO20</td>\n",
       "      <td>484010722</td>\n",
       "      <td>Kenneth Cole New York Women's KC4944 Automatic...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>I love thiswatch it keeps time wonderfully</td>\n",
       "      <td>I love this watch it keeps time wonderfully.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>27324930</td>\n",
       "      <td>R2HLE8WKZSU3NL</td>\n",
       "      <td>B00DKYC7TK</td>\n",
       "      <td>361166390</td>\n",
       "      <td>Ritche 22mm Black Stainless Steel Bracelet Wat...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>Scratches</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>7211452</td>\n",
       "      <td>R31U3UH5AZ42LL</td>\n",
       "      <td>B000EQS1JW</td>\n",
       "      <td>958035625</td>\n",
       "      <td>Citizen Men's BM8180-03E Eco-Drive Stainless S...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>It works well on me. However, I found cheaper ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>12733322</td>\n",
       "      <td>R2SV659OUJ945Y</td>\n",
       "      <td>B00A6GFD7S</td>\n",
       "      <td>765328221</td>\n",
       "      <td>Orient ER27009B Men's Symphony Automatic Stain...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Beautiful face, but cheap sounding links</td>\n",
       "      <td>Beautiful watch face.  The band looks nice all...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US      3653882  R3O9SGZBVQBV76  B00FALQ1ZC       937001370   \n",
       "1          US     14661224   RKH8BNC3L5DLF  B00D3RGO20       484010722   \n",
       "2          US     27324930  R2HLE8WKZSU3NL  B00DKYC7TK       361166390   \n",
       "3          US      7211452  R31U3UH5AZ42LL  B000EQS1JW       958035625   \n",
       "4          US     12733322  R2SV659OUJ945Y  B00A6GFD7S       765328221   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  Invicta Women's 15150 \"Angel\" 18k Yellow Gold ...          Watches   \n",
       "1  Kenneth Cole New York Women's KC4944 Automatic...          Watches   \n",
       "2  Ritche 22mm Black Stainless Steel Bracelet Wat...          Watches   \n",
       "3  Citizen Men's BM8180-03E Eco-Drive Stainless S...          Watches   \n",
       "4  Orient ER27009B Men's Symphony Automatic Stain...          Watches   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5              0            0    N                 Y   \n",
       "2            2              1            1    N                 Y   \n",
       "3            5              0            0    N                 Y   \n",
       "4            4              0            0    N                 Y   \n",
       "\n",
       "                              review_headline  \\\n",
       "0                                  Five Stars   \n",
       "1  I love thiswatch it keeps time wonderfully   \n",
       "2                                   Two Stars   \n",
       "3                                  Five Stars   \n",
       "4    Beautiful face, but cheap sounding links   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  Absolutely love this watch! Get compliments al...  2015-08-31  \n",
       "1       I love this watch it keeps time wonderfully.  2015-08-31  \n",
       "2                                          Scratches  2015-08-31  \n",
       "3  It works well on me. However, I found cheaper ...  2015-08-31  \n",
       "4  Beautiful watch face.  The band looks nice all...  2015-08-31  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace            0\n",
       "customer_id            0\n",
       "review_id              0\n",
       "product_id             0\n",
       "product_parent         0\n",
       "product_title          2\n",
       "product_category       0\n",
       "star_rating            0\n",
       "helpful_votes          0\n",
       "total_votes            0\n",
       "vine                   0\n",
       "verified_purchase      0\n",
       "review_headline        7\n",
       "review_body          148\n",
       "review_date            4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 960056 entries, 0 to 960055\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   marketplace        960056 non-null  object\n",
      " 1   customer_id        960056 non-null  int64 \n",
      " 2   review_id          960056 non-null  object\n",
      " 3   product_id         960056 non-null  object\n",
      " 4   product_parent     960056 non-null  int64 \n",
      " 5   product_title      960054 non-null  object\n",
      " 6   product_category   960056 non-null  object\n",
      " 7   star_rating        960056 non-null  int64 \n",
      " 8   helpful_votes      960056 non-null  int64 \n",
      " 9   total_votes        960056 non-null  int64 \n",
      " 10  vine               960056 non-null  object\n",
      " 11  verified_purchase  960056 non-null  object\n",
      " 12  review_headline    960049 non-null  object\n",
      " 13  review_body        960056 non-null  object\n",
      " 14  review_date        960052 non-null  object\n",
      "dtypes: int64(5), object(10)\n",
      "memory usage: 109.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Remove if the review without review boday.\n",
    "df.dropna(subset=['review_body'], inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first 1000 data as training data.\n",
    "data = df.loc[:999, 'review_body'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing and Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load stopwords and stemmer function from NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords that we use from nltk library: \n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", \"'s\", \"'m\", 'br', 'watch']\n"
     ]
    }
   ],
   "source": [
    "# Use nltk's English stopwords.\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.append(\"'s\")\n",
    "stopwords.append(\"'m\")\n",
    "stopwords.append(\"br\") #html <br>\n",
    "stopwords.append(\"watch\")\n",
    "\n",
    "print(\"Stopwords that we use from nltk library: \")\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely love this watch! Get compliments almost every time I wear it. Dainty.\n",
      "['absolut', 'love', 'get', 'compliment', 'almost', 'everi', 'time', 'wear', 'dainti']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Define functions to tokenize and stem reviews.\n",
    "def tokenization_and_stemming(text):\n",
    "    # exclude stop words and tokenize the document, generate a list of string\n",
    "    tokens = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word.lower() not in stopwords:\n",
    "            tokens.append(word.lower())\n",
    "    \n",
    "    # filter out any tokens not containing letters such as numeric tokens and raw punctuation.\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            filtered_tokens.append(token)\n",
    "    \n",
    "    # stemming.\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "# Test function with the first review.\n",
    "print(data[0])\n",
    "print(tokenization_and_stemming(data[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afterward', 'alon', 'alreadi', 'alway', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becom', 'besid', 'cri', 'describ', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'otherwis', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1000x239 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6891 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Define vectorizer parameters, and use TfidfVectorizer to create tf-idf matrix\n",
    "tfidf_model = TfidfVectorizer(max_df=0.99, max_features=1000, min_df=0.01, stop_words='english', use_idf=True, \n",
    "                                tokenizer=tokenization_and_stemming, ngram_range=(1,1))\n",
    "\n",
    "# Fit the vectorizer to synopses\n",
    "tfidf_matrix = tfidf_model.fit_transform(data)\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.5125863, 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       ...,\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.       , 0.5125863, 0.       , ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        ...,\n",
       "        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "         0.       ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abl', 'absolut', 'accur', 'actual', 'adjust', 'alarm', 'alreadi', 'alway', 'amaz', 'amazon', 'anoth', 'arm', 'arriv', 'automat', 'awesom', 'bad', 'band', 'batteri', 'beauti', 'best', 'better', 'big', 'bit', 'black', 'blue', 'bought', 'box', 'bracelet', 'brand', 'break', 'bright', 'broke', 'button', 'buy', 'ca', 'came', 'case', 'casio', 'chang', 'cheap', 'clasp', 'classi', 'clock', 'color', 'come', 'comfort', 'compliment', 'cool', 'cost', 'crown', 'crystal', 'dark', 'date', 'daughter', 'day', 'deal', 'definit', 'deliveri', 'design', 'dial', 'differ', 'difficult', 'disappoint', 'display', 'dress', 'durabl', 'easi', 'easili', 'end', 'everi', 'everyday', 'everyth', 'exact', 'excel', 'expect', 'expens', 'face', 'fair', 'far', 'fast', 'featur', 'feel', 'fell', 'fine', 'finish', 'fit', 'function', 'gave', 'gift', 'gold', 'good', 'got', 'great', 'hand', 'happi', 'hard', 'heavi', 'high', 'hold', 'honest', 'hope', 'hour', 'howev', 'husband', 'includ', 'instruct', 'invicta', 'issu', 'item', 'kept', 'know', 'larg', 'leather', 'light', 'like', 'link', 'littl', 'long', 'look', 'lot', 'love', 'low', 'make', 'mani', 'metal', 'minut', 'model', 'money', 'month', 'movement', 'need', 'new', 'nice', 'night', 'normal', 'number', 'old', 'open', 'oper', 'order', 'origin', 'overal', 'packag', 'paid', 'pay', 'perfect', 'perform', 'person', 'pictur', 'piec', 'pin', 'place', 'plastic', 'pleas', 'point', 'press', 'pretti', 'price', 'problem', 'product', 'purchas', 'qualiti', 'quick', 'quit', 'rate', 'read', 'real', 'realli', 'reason', 'receiv', 'recommend', 'red', 'remov', 'replac', 'resist', 'return', 'review', 'right', 'run', 'said', 'say', 'screw', 'second', 'seiko', 'seller', 'send', 'sent', 'set', 'sever', 'ship', 'short', 'simpl', 'sinc', 'size', 'small', 'smaller', 'solid', 'someth', 'somewhat', 'son', 'star', 'start', 'stop', 'strap', 'sturdi', 'style', 'stylish', 'super', 'sure', 'surpris', 'swim', 'tell', 'thank', 'thing', 'think', 'thought', 'time', 'timex', 'tini', 'tri', 'turn', 'use', 'valu', 'want', 'watch', 'water', 'way', 'wear', 'week', 'weight', 'went', 'wife', 'wind', 'wish', 'work', 'worn', 'worth', 'wrist', 'year']\n"
     ]
    }
   ],
   "source": [
    "# Save terms identified by TF-IDF\n",
    "tf_selected_words = tfidf_model.get_feature_names()\n",
    "print(tf_selected_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# define number of clusters\n",
    "num_clusters = 10\n",
    "km = KMeans(n_clusters= num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely love this watch! Get compliments al...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love this watch it keeps time wonderfully.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scratches</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It works well on me. However, I found cheaper ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beautiful watch face.  The band looks nice all...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i love this watch for my purpose, about the pe...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>for my wife and she loved it, looks great and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I was about to buy this thinking it was a Swis...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Watch is perfect. Rugged with the metal &amp;#34;B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Great quality and build.&lt;br /&gt;The motors are r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  cluster\n",
       "0  Absolutely love this watch! Get compliments al...        8\n",
       "1       I love this watch it keeps time wonderfully.        8\n",
       "2                                          Scratches        2\n",
       "3  It works well on me. However, I found cheaper ...        2\n",
       "4  Beautiful watch face.  The band looks nice all...        0\n",
       "5  i love this watch for my purpose, about the pe...        8\n",
       "6  for my wife and she loved it, looks great and ...        1\n",
       "7  I was about to buy this thinking it was a Swis...        2\n",
       "8  Watch is perfect. Rugged with the metal &#34;B...        1\n",
       "9  Great quality and build.<br />The motors are r...        2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze K-means Result\n",
    "# Create dataframe films from all of the input files.\n",
    "product = {'review': df[:1000].review_body, 'cluster': clusters}\n",
    "frame = pd.DataFrame(product, columns = ['review', 'cluster'])\n",
    "frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster\n",
       "2      429\n",
       "8       97\n",
       "0       91\n",
       "7       77\n",
       "1       70\n",
       "5       64\n",
       "3       63\n",
       "6       55\n",
       "4       30\n",
       "9       24"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of reviews included in each cluster.\n",
    "frame['cluster'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00180128, 0.00225074, 0.01222436, ..., 0.0023171 , 0.04946018,\n",
       "        0.02021277],\n",
       "       [0.00460702, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.01694012],\n",
       "       [0.00775552, 0.00317823, 0.00256665, ..., 0.00785089, 0.01175987,\n",
       "        0.01899595],\n",
       "       ...,\n",
       "       [0.00365974, 0.02944326, 0.        , ..., 0.00652463, 0.02104069,\n",
       "        0.        ],\n",
       "       [0.        , 0.03238075, 0.        , ..., 0.01398553, 0.01444061,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.02074231, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# km.cluster_centers_ denotes the importances of each items in centroid\n",
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 words:band,look,leather,wrist,good,nice,\n",
      "Cluster 0 reviews (91 reviews): \n",
      "Cluster 1 words:great,look,price,comfort,product,work,\n",
      "Cluster 1 reviews (70 reviews): \n",
      "Cluster 2 words:work,look,time,use,day,good,\n",
      "Cluster 2 reviews (429 reviews): \n",
      "Cluster 3 words:good,product,price,love,big,qualiti,\n",
      "Cluster 3 reviews (63 reviews): \n",
      "Cluster 4 words:excel,product,price,fast,qualiti,good,\n",
      "Cluster 4 reviews (30 reviews): \n",
      "Cluster 5 words:like,look,work,face,nice,big,\n",
      "Cluster 5 reviews (64 reviews): \n",
      "Cluster 6 words:nice,price,look,realli,good,love,\n",
      "Cluster 6 reviews (55 reviews): \n",
      "Cluster 7 words:perfect,beauti,fit,wear,great,realli,\n",
      "Cluster 7 reviews (77 reviews): \n",
      "Cluster 8 words:love,wife,husband,look,color,gift,\n",
      "Cluster 8 reviews (97 reviews): \n",
      "Cluster 9 words:expect,clock,everyth,thank,nice,time,\n",
      "Cluster 9 reviews (24 reviews): \n"
     ]
    }
   ],
   "source": [
    "# Clustering result by K-means\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "cluster_keywords_summary = {}\n",
    "for i in range(num_clusters):\n",
    "    print (\"Cluster \" + str(i) + \" words:\", end='')\n",
    "    cluster_keywords_summary[i] = []\n",
    "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
    "        cluster_keywords_summary[i].append(tf_selected_words[ind])\n",
    "        print (tf_selected_words[ind] + \",\", end='')\n",
    "    print ()\n",
    "\n",
    "    cluster_reviews = frame[frame.cluster==i].review.tolist()\n",
    "    print (\"Cluster \" + str(i) + \" reviews (\" + str(len(cluster_reviews)) + \" reviews): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling - Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LDA for clustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02961289 0.02961349 0.0296127  ... 0.02961471 0.41336188 0.02961335]\n",
      " [0.04146564 0.04146658 0.04146146 ... 0.04147284 0.04148658 0.0414698 ]\n",
      " [0.1        0.1        0.1        ... 0.1        0.1        0.1       ]\n",
      " ...\n",
      " [0.05000009 0.05       0.05       ... 0.05       0.05       0.05000115]\n",
      " [0.03336732 0.03336634 0.03337834 ... 0.03336842 0.03336949 0.03337937]\n",
      " [0.03361466 0.03361466 0.0336204  ... 0.03362321 0.17279604 0.55823218]]\n"
     ]
    }
   ],
   "source": [
    "# document topic matrix for tfida_matrix_lda\n",
    "lda_output = lda.fit_transform(tfidf_matrix)\n",
    "print(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1        0.10000043 0.10006528 ... 0.10001659 0.10001513 5.37321507]\n",
      " [0.10000707 0.10001138 0.1        ... 0.22495653 0.10000407 0.10000758]\n",
      " [0.10000079 0.10000545 0.1000089  ... 5.91058679 0.10000177 0.57897091]\n",
      " ...\n",
      " [0.10000453 0.10001555 0.10000129 ... 0.10000387 2.87478919 0.10000443]\n",
      " [0.10001472 7.51748258 0.10000002 ... 0.10000458 0.10000136 0.10000565]\n",
      " [1.02152978 0.10007015 2.65366751 ... 0.10004474 3.91535088 3.35201994]]\n"
     ]
    }
   ],
   "source": [
    "# Topics and words matrix\n",
    "topic_word = lda.components_\n",
    "print(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc5</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc6</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc7</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc8</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc9</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  Topic8  \\\n",
       "Doc0    0.03    0.03    0.03    0.03    0.03    0.03    0.35    0.03    0.41   \n",
       "Doc1    0.04    0.04    0.04    0.63    0.04    0.04    0.04    0.04    0.04   \n",
       "Doc2    0.10    0.10    0.10    0.10    0.10    0.10    0.10    0.10    0.10   \n",
       "Doc3    0.03    0.03    0.03    0.03    0.74    0.03    0.03    0.03    0.03   \n",
       "Doc4    0.47    0.02    0.02    0.02    0.38    0.02    0.02    0.02    0.02   \n",
       "Doc5    0.04    0.04    0.67    0.04    0.04    0.04    0.04    0.04    0.04   \n",
       "Doc6    0.03    0.03    0.35    0.03    0.03    0.39    0.03    0.03    0.03   \n",
       "Doc7    0.03    0.03    0.03    0.03    0.72    0.03    0.03    0.03    0.03   \n",
       "Doc8    0.02    0.02    0.02    0.02    0.55    0.02    0.02    0.27    0.02   \n",
       "Doc9    0.03    0.03    0.03    0.37    0.03    0.03    0.03    0.03    0.03   \n",
       "\n",
       "      Topic9  topic  \n",
       "Doc0    0.03      8  \n",
       "Doc1    0.04      3  \n",
       "Doc2    0.10      0  \n",
       "Doc3    0.03      4  \n",
       "Doc4    0.02      0  \n",
       "Doc5    0.04      2  \n",
       "Doc6    0.03      5  \n",
       "Doc7    0.03      4  \n",
       "Doc8    0.02      4  \n",
       "Doc9    0.41      9  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_names = [\"Topic\" + str(i) for i in range(lda.n_components)]\n",
    "doc_names = ['Doc' + str(i) for i in range(len(data))]\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topic_names, index=doc_names)\n",
    "\n",
    "# get dominant topic for each document\n",
    "topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['topic'] = topic\n",
    "df_document_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic\n",
       "4    209\n",
       "9    182\n",
       "5    112\n",
       "3    105\n",
       "0    101\n",
       "1     86\n",
       "7     65\n",
       "2     56\n",
       "8     54\n",
       "6     30"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_topic['topic'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1        0.10000043 0.10006528 ... 0.10001659 0.10001513 5.37321507]\n",
      " [0.10000707 0.10001138 0.1        ... 0.22495653 0.10000407 0.10000758]\n",
      " [0.10000079 0.10000545 0.1000089  ... 5.91058679 0.10000177 0.57897091]\n",
      " ...\n",
      " [0.10000453 0.10001555 0.10000129 ... 0.10000387 2.87478919 0.10000443]\n",
      " [0.10001472 7.51748258 0.10000002 ... 0.10000458 0.10000136 0.10000565]\n",
      " [1.02152978 0.10007015 2.65366751 ... 0.10004474 3.91535088 3.35201994]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accur</th>\n",
       "      <th>actual</th>\n",
       "      <th>adjust</th>\n",
       "      <th>alarm</th>\n",
       "      <th>alreadi</th>\n",
       "      <th>alway</th>\n",
       "      <th>amaz</th>\n",
       "      <th>amazon</th>\n",
       "      <th>...</th>\n",
       "      <th>weight</th>\n",
       "      <th>went</th>\n",
       "      <th>wife</th>\n",
       "      <th>wind</th>\n",
       "      <th>wish</th>\n",
       "      <th>work</th>\n",
       "      <th>worn</th>\n",
       "      <th>worth</th>\n",
       "      <th>wrist</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100065</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>2.279286</td>\n",
       "      <td>0.100005</td>\n",
       "      <td>0.100008</td>\n",
       "      <td>0.100008</td>\n",
       "      <td>0.568677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100120</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.042194</td>\n",
       "      <td>0.100004</td>\n",
       "      <td>0.100017</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>5.373215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100013</td>\n",
       "      <td>0.100019</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100003</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>7.739703</td>\n",
       "      <td>0.100035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100003</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.639144</td>\n",
       "      <td>1.897503</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.224957</td>\n",
       "      <td>0.100004</td>\n",
       "      <td>0.100008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>0.100001</td>\n",
       "      <td>0.100005</td>\n",
       "      <td>0.100009</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.100056</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.445684</td>\n",
       "      <td>0.100008</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.242009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100003</td>\n",
       "      <td>0.100042</td>\n",
       "      <td>11.742352</td>\n",
       "      <td>2.291155</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>0.100003</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>5.910587</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>0.578971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>0.100003</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100004</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>2.192505</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100009</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100003</td>\n",
       "      <td>0.100008</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100003</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>0.100004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>3.273765</td>\n",
       "      <td>0.178173</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>1.990626</td>\n",
       "      <td>0.475633</td>\n",
       "      <td>1.389875</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>1.432605</td>\n",
       "      <td>0.940885</td>\n",
       "      <td>4.291749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100028</td>\n",
       "      <td>0.100053</td>\n",
       "      <td>0.100013</td>\n",
       "      <td>0.100016</td>\n",
       "      <td>0.100070</td>\n",
       "      <td>4.565381</td>\n",
       "      <td>3.303069</td>\n",
       "      <td>0.100051</td>\n",
       "      <td>6.923597</td>\n",
       "      <td>2.692868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             abl   absolut     accur    actual    adjust     alarm   alreadi  \\\n",
       "Topic0  0.100000  0.100000  0.100065  0.100000  0.100011  2.279286  0.100005   \n",
       "Topic1  0.100007  0.100011  0.100000  0.100013  0.100019  0.100000  0.100003   \n",
       "Topic2  0.100001  0.100005  0.100009  0.100006  0.100056  0.100000  3.445684   \n",
       "Topic3  0.100003  0.100001  0.100000  0.100004  0.100000  0.100000  0.100001   \n",
       "Topic4  3.273765  0.178173  0.100012  1.990626  0.475633  1.389875  0.100015   \n",
       "\n",
       "           alway      amaz    amazon  ...    weight      went       wife  \\\n",
       "Topic0  0.100008  0.100008  0.568677  ...  0.100000  0.100120   0.100000   \n",
       "Topic1  0.100001  7.739703  0.100035  ...  0.100002  0.100000   0.100003   \n",
       "Topic2  0.100008  0.100000  1.242009  ...  0.100003  0.100042  11.742352   \n",
       "Topic3  2.192505  0.100002  0.100000  ...  0.100009  0.100000   0.100002   \n",
       "Topic4  1.432605  0.940885  4.291749  ...  0.100028  0.100053   0.100013   \n",
       "\n",
       "            wind      wish      work      worn     worth     wrist      year  \n",
       "Topic0  0.100000  0.100000  3.042194  0.100004  0.100017  0.100015  5.373215  \n",
       "Topic1  0.100000  2.639144  1.897503  0.100000  0.224957  0.100004  0.100008  \n",
       "Topic2  2.291155  0.100002  0.100003  0.100000  5.910587  0.100002  0.578971  \n",
       "Topic3  0.100000  0.100003  0.100008  0.100000  0.100003  0.100001  0.100004  \n",
       "Topic4  0.100016  0.100070  4.565381  3.303069  0.100051  6.923597  2.692868  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topic word matrix\n",
    "print(lda.components_)\n",
    "df_topic_words = pd.DataFrame(lda.components_)\n",
    "\n",
    "# column and index\n",
    "df_topic_words.columns = tfidf_model.get_feature_names()\n",
    "df_topic_words.index = topic_names\n",
    "df_topic_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>beauti</td>\n",
       "      <td>broke</td>\n",
       "      <td>batteri</td>\n",
       "      <td>week</td>\n",
       "      <td>love</td>\n",
       "      <td>arriv</td>\n",
       "      <td>color</td>\n",
       "      <td>band</td>\n",
       "      <td>year</td>\n",
       "      <td>water</td>\n",
       "      <td>clock</td>\n",
       "      <td>resist</td>\n",
       "      <td>fell</td>\n",
       "      <td>day</td>\n",
       "      <td>anoth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>nice</td>\n",
       "      <td>awesom</td>\n",
       "      <td>thank</td>\n",
       "      <td>amaz</td>\n",
       "      <td>super</td>\n",
       "      <td>fast</td>\n",
       "      <td>price</td>\n",
       "      <td>ship</td>\n",
       "      <td>simpl</td>\n",
       "      <td>set</td>\n",
       "      <td>love</td>\n",
       "      <td>look</td>\n",
       "      <td>great</td>\n",
       "      <td>instruct</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>perfect</td>\n",
       "      <td>wife</td>\n",
       "      <td>gift</td>\n",
       "      <td>love</td>\n",
       "      <td>worth</td>\n",
       "      <td>recommend</td>\n",
       "      <td>happi</td>\n",
       "      <td>quick</td>\n",
       "      <td>buy</td>\n",
       "      <td>alreadi</td>\n",
       "      <td>movement</td>\n",
       "      <td>gave</td>\n",
       "      <td>look</td>\n",
       "      <td>high</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>good</td>\n",
       "      <td>love</td>\n",
       "      <td>like</td>\n",
       "      <td>qualiti</td>\n",
       "      <td>realli</td>\n",
       "      <td>pretti</td>\n",
       "      <td>price</td>\n",
       "      <td>better</td>\n",
       "      <td>person</td>\n",
       "      <td>look</td>\n",
       "      <td>pictur</td>\n",
       "      <td>beauti</td>\n",
       "      <td>time</td>\n",
       "      <td>month</td>\n",
       "      <td>came</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>look</td>\n",
       "      <td>band</td>\n",
       "      <td>face</td>\n",
       "      <td>like</td>\n",
       "      <td>great</td>\n",
       "      <td>pictur</td>\n",
       "      <td>nice</td>\n",
       "      <td>watch</td>\n",
       "      <td>cheap</td>\n",
       "      <td>leather</td>\n",
       "      <td>feel</td>\n",
       "      <td>make</td>\n",
       "      <td>time</td>\n",
       "      <td>design</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>great</td>\n",
       "      <td>excel</td>\n",
       "      <td>work</td>\n",
       "      <td>product</td>\n",
       "      <td>expect</td>\n",
       "      <td>price</td>\n",
       "      <td>look</td>\n",
       "      <td>seller</td>\n",
       "      <td>exact</td>\n",
       "      <td>item</td>\n",
       "      <td>everyth</td>\n",
       "      <td>perfect</td>\n",
       "      <td>fit</td>\n",
       "      <td>valu</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>strap</td>\n",
       "      <td>compliment</td>\n",
       "      <td>invicta</td>\n",
       "      <td>lot</td>\n",
       "      <td>buy</td>\n",
       "      <td>dress</td>\n",
       "      <td>easili</td>\n",
       "      <td>everi</td>\n",
       "      <td>style</td>\n",
       "      <td>think</td>\n",
       "      <td>love</td>\n",
       "      <td>sever</td>\n",
       "      <td>short</td>\n",
       "      <td>anoth</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>husband</td>\n",
       "      <td>love</td>\n",
       "      <td>deliveri</td>\n",
       "      <td>pleas</td>\n",
       "      <td>big</td>\n",
       "      <td>stylish</td>\n",
       "      <td>heavi</td>\n",
       "      <td>receiv</td>\n",
       "      <td>got</td>\n",
       "      <td>daughter</td>\n",
       "      <td>look</td>\n",
       "      <td>piec</td>\n",
       "      <td>surpris</td>\n",
       "      <td>beauti</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 8</th>\n",
       "      <td>absolut</td>\n",
       "      <td>wear</td>\n",
       "      <td>cool</td>\n",
       "      <td>bought</td>\n",
       "      <td>want</td>\n",
       "      <td>love</td>\n",
       "      <td>bad</td>\n",
       "      <td>fine</td>\n",
       "      <td>money</td>\n",
       "      <td>time</td>\n",
       "      <td>work</td>\n",
       "      <td>reason</td>\n",
       "      <td>swim</td>\n",
       "      <td>tell</td>\n",
       "      <td>beauti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 9</th>\n",
       "      <td>use</td>\n",
       "      <td>band</td>\n",
       "      <td>look</td>\n",
       "      <td>work</td>\n",
       "      <td>comfort</td>\n",
       "      <td>day</td>\n",
       "      <td>great</td>\n",
       "      <td>time</td>\n",
       "      <td>far</td>\n",
       "      <td>easi</td>\n",
       "      <td>good</td>\n",
       "      <td>light</td>\n",
       "      <td>function</td>\n",
       "      <td>deal</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word 0      Word 1    Word 2   Word 3   Word 4     Word 5  Word 6  \\\n",
       "Topic 0   beauti       broke   batteri     week     love      arriv   color   \n",
       "Topic 1     nice      awesom     thank     amaz    super       fast   price   \n",
       "Topic 2  perfect        wife      gift     love    worth  recommend   happi   \n",
       "Topic 3     good        love      like  qualiti   realli     pretti   price   \n",
       "Topic 4     look        band      face     like    great     pictur    nice   \n",
       "Topic 5    great       excel      work  product   expect      price    look   \n",
       "Topic 6    strap  compliment   invicta      lot      buy      dress  easili   \n",
       "Topic 7  husband        love  deliveri    pleas      big    stylish   heavi   \n",
       "Topic 8  absolut        wear      cool   bought     want       love     bad   \n",
       "Topic 9      use        band      look     work  comfort        day   great   \n",
       "\n",
       "         Word 7  Word 8    Word 9   Word 10  Word 11   Word 12   Word 13  \\\n",
       "Topic 0    band    year     water     clock   resist      fell       day   \n",
       "Topic 1    ship   simpl       set      love     look     great  instruct   \n",
       "Topic 2   quick     buy   alreadi  movement     gave      look      high   \n",
       "Topic 3  better  person      look    pictur   beauti      time     month   \n",
       "Topic 4   watch   cheap   leather      feel     make      time    design   \n",
       "Topic 5  seller   exact      item   everyth  perfect       fit      valu   \n",
       "Topic 6   everi   style     think      love    sever     short     anoth   \n",
       "Topic 7  receiv     got  daughter      look     piec   surpris    beauti   \n",
       "Topic 8    fine   money      time      work   reason      swim      tell   \n",
       "Topic 9    time     far      easi      good    light  function      deal   \n",
       "\n",
       "        Word 14  \n",
       "Topic 0   anoth  \n",
       "Topic 1    hard  \n",
       "Topic 2    nice  \n",
       "Topic 3    came  \n",
       "Topic 4    size  \n",
       "Topic 5    good  \n",
       "Topic 6   watch  \n",
       "Topic 7    time  \n",
       "Topic 8  beauti  \n",
       "Topic 9    like  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print top n keywords for each topic\n",
    "def print_topic_words(tfidf_model, lda_model, n_words):\n",
    "    words = np.array(tfidf_model.get_feature_names())\n",
    "    topic_words = []\n",
    "    # for each topic, we have words weight\n",
    "    for topic_words_weights in lda_model.components_:\n",
    "        top_words = topic_words_weights.argsort()[::-1][:n_words]\n",
    "        topic_words.append(words.take(top_words))\n",
    "    return topic_words\n",
    "\n",
    "topic_keywords = print_topic_words(tfidf_model=tfidf_model, lda_model=lda, n_words=15)        \n",
    "\n",
    "df_topic_words = pd.DataFrame(topic_keywords)\n",
    "df_topic_words.columns = ['Word '+str(i) for i in range(df_topic_words.shape[1])]\n",
    "df_topic_words.index = ['Topic '+str(i) for i in range(df_topic_words.shape[0])]\n",
    "df_topic_words"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
