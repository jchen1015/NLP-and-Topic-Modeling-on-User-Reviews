{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/judychen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/judychen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "b'Skipping line 8704: expected 15 fields, saw 22\\nSkipping line 16933: expected 15 fields, saw 22\\nSkipping line 23726: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 85637: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 132136: expected 15 fields, saw 22\\nSkipping line 158070: expected 15 fields, saw 22\\nSkipping line 166007: expected 15 fields, saw 22\\nSkipping line 171877: expected 15 fields, saw 22\\nSkipping line 177756: expected 15 fields, saw 22\\nSkipping line 181773: expected 15 fields, saw 22\\nSkipping line 191085: expected 15 fields, saw 22\\nSkipping line 196273: expected 15 fields, saw 22\\nSkipping line 196331: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 197000: expected 15 fields, saw 22\\nSkipping line 197011: expected 15 fields, saw 22\\nSkipping line 197432: expected 15 fields, saw 22\\nSkipping line 208016: expected 15 fields, saw 22\\nSkipping line 214110: expected 15 fields, saw 22\\nSkipping line 244328: expected 15 fields, saw 22\\nSkipping line 248519: expected 15 fields, saw 22\\nSkipping line 254936: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 272057: expected 15 fields, saw 22\\nSkipping line 293214: expected 15 fields, saw 22\\nSkipping line 310507: expected 15 fields, saw 22\\nSkipping line 312306: expected 15 fields, saw 22\\nSkipping line 316296: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 336028: expected 15 fields, saw 22\\nSkipping line 344885: expected 15 fields, saw 22\\nSkipping line 352551: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 408773: expected 15 fields, saw 22\\nSkipping line 434535: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 581593: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 652409: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "# Import data.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df = pd.read_csv('watch_reviews.tsv', sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>3653882</td>\n",
       "      <td>R3O9SGZBVQBV76</td>\n",
       "      <td>B00FALQ1ZC</td>\n",
       "      <td>937001370</td>\n",
       "      <td>Invicta Women's 15150 \"Angel\" 18k Yellow Gold ...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Absolutely love this watch! Get compliments al...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>14661224</td>\n",
       "      <td>RKH8BNC3L5DLF</td>\n",
       "      <td>B00D3RGO20</td>\n",
       "      <td>484010722</td>\n",
       "      <td>Kenneth Cole New York Women's KC4944 Automatic...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>I love thiswatch it keeps time wonderfully</td>\n",
       "      <td>I love this watch it keeps time wonderfully.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>27324930</td>\n",
       "      <td>R2HLE8WKZSU3NL</td>\n",
       "      <td>B00DKYC7TK</td>\n",
       "      <td>361166390</td>\n",
       "      <td>Ritche 22mm Black Stainless Steel Bracelet Wat...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>Scratches</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>7211452</td>\n",
       "      <td>R31U3UH5AZ42LL</td>\n",
       "      <td>B000EQS1JW</td>\n",
       "      <td>958035625</td>\n",
       "      <td>Citizen Men's BM8180-03E Eco-Drive Stainless S...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>It works well on me. However, I found cheaper ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>12733322</td>\n",
       "      <td>R2SV659OUJ945Y</td>\n",
       "      <td>B00A6GFD7S</td>\n",
       "      <td>765328221</td>\n",
       "      <td>Orient ER27009B Men's Symphony Automatic Stain...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Beautiful face, but cheap sounding links</td>\n",
       "      <td>Beautiful watch face.  The band looks nice all...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US      3653882  R3O9SGZBVQBV76  B00FALQ1ZC       937001370   \n",
       "1          US     14661224   RKH8BNC3L5DLF  B00D3RGO20       484010722   \n",
       "2          US     27324930  R2HLE8WKZSU3NL  B00DKYC7TK       361166390   \n",
       "3          US      7211452  R31U3UH5AZ42LL  B000EQS1JW       958035625   \n",
       "4          US     12733322  R2SV659OUJ945Y  B00A6GFD7S       765328221   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  Invicta Women's 15150 \"Angel\" 18k Yellow Gold ...          Watches   \n",
       "1  Kenneth Cole New York Women's KC4944 Automatic...          Watches   \n",
       "2  Ritche 22mm Black Stainless Steel Bracelet Wat...          Watches   \n",
       "3  Citizen Men's BM8180-03E Eco-Drive Stainless S...          Watches   \n",
       "4  Orient ER27009B Men's Symphony Automatic Stain...          Watches   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5              0            0    N                 Y   \n",
       "2            2              1            1    N                 Y   \n",
       "3            5              0            0    N                 Y   \n",
       "4            4              0            0    N                 Y   \n",
       "\n",
       "                              review_headline  \\\n",
       "0                                  Five Stars   \n",
       "1  I love thiswatch it keeps time wonderfully   \n",
       "2                                   Two Stars   \n",
       "3                                  Five Stars   \n",
       "4    Beautiful face, but cheap sounding links   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  Absolutely love this watch! Get compliments al...  2015-08-31  \n",
       "1       I love this watch it keeps time wonderfully.  2015-08-31  \n",
       "2                                          Scratches  2015-08-31  \n",
       "3  It works well on me. However, I found cheaper ...  2015-08-31  \n",
       "4  Beautiful watch face.  The band looks nice all...  2015-08-31  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace            0\n",
       "customer_id            0\n",
       "review_id              0\n",
       "product_id             0\n",
       "product_parent         0\n",
       "product_title          2\n",
       "product_category       0\n",
       "star_rating            0\n",
       "helpful_votes          0\n",
       "total_votes            0\n",
       "vine                   0\n",
       "verified_purchase      0\n",
       "review_headline        7\n",
       "review_body          148\n",
       "review_date            4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 960056 entries, 0 to 960055\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   marketplace        960056 non-null  object\n",
      " 1   customer_id        960056 non-null  int64 \n",
      " 2   review_id          960056 non-null  object\n",
      " 3   product_id         960056 non-null  object\n",
      " 4   product_parent     960056 non-null  int64 \n",
      " 5   product_title      960054 non-null  object\n",
      " 6   product_category   960056 non-null  object\n",
      " 7   star_rating        960056 non-null  int64 \n",
      " 8   helpful_votes      960056 non-null  int64 \n",
      " 9   total_votes        960056 non-null  int64 \n",
      " 10  vine               960056 non-null  object\n",
      " 11  verified_purchase  960056 non-null  object\n",
      " 12  review_headline    960049 non-null  object\n",
      " 13  review_body        960056 non-null  object\n",
      " 14  review_date        960052 non-null  object\n",
      "dtypes: int64(5), object(10)\n",
      "memory usage: 109.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Remove if the review without review boday.\n",
    "df.dropna(subset=['review_body'], inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first 15000 data as training data.\n",
    "data = df.loc[:14999, 'review_body'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing and Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load stopwords and stemmer function from NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords that we use from nltk library: \n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", \"'s\", \"'m\", 'br', 'watch']\n"
     ]
    }
   ],
   "source": [
    "# Use nltk's English stopwords.\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.append(\"'s\")\n",
    "stopwords.append(\"'m\")\n",
    "stopwords.append(\"br\") #html <br>\n",
    "stopwords.append(\"watch\")\n",
    "\n",
    "print(\"Stopwords that we use from nltk library: \")\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely love this watch! Get compliments almost every time I wear it. Dainty.\n",
      "['absolut', 'love', 'get', 'compliment', 'almost', 'everi', 'time', 'wear', 'dainti']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Define functions to tokenize and stem reviews.\n",
    "def tokenization_and_stemming(text):\n",
    "    # exclude stop words and tokenize the document, generate a list of string\n",
    "    tokens = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word.lower() not in stopwords:\n",
    "            tokens.append(word.lower())\n",
    "    \n",
    "    # filter out any tokens not containing letters such as numeric tokens and raw punctuation.\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            filtered_tokens.append(token)\n",
    "    \n",
    "    # stemming.\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "# Test function with the first review.\n",
    "print(data[0])\n",
    "print(tokenization_and_stemming(data[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afterward', 'alon', 'alreadi', 'alway', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becom', 'besid', 'cri', 'describ', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'otherwis', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<15000x227 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 100770 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Define vectorizer parameters, and use TfidfVectorizer to create tf-idf matrix\n",
    "tfidf_model = TfidfVectorizer(max_df=0.99, max_features=1000, min_df=0.01, stop_words='english', use_idf=True, \n",
    "                                tokenizer=tokenization_and_stemming, ngram_range=(1,1))\n",
    "\n",
    "# Fit the vectorizer to synopses\n",
    "tfidf_matrix = tfidf_model.fit_transform(data)\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.52538715, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.52538715, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abl', 'absolut', 'accur', 'actual', 'adjust', 'alarm', 'alreadi', 'alway', 'amaz', 'amazon', 'anoth', 'anyth', 'appear', 'arriv', 'attract', 'automat', 'awesom', 'bad', 'band', 'batteri', 'beauti', 'best', 'better', 'big', 'bit', 'black', 'blue', 'bought', 'box', 'bracelet', 'brand', 'broke', 'button', 'buy', 'ca', 'came', 'case', 'casio', 'chang', 'cheap', 'clasp', 'classi', 'clear', 'clock', 'color', 'come', 'comfort', 'compliment', 'cool', 'cost', 'coupl', 'crystal', 'cute', 'dark', 'date', 'day', 'deal', 'definit', 'design', 'dial', 'differ', 'difficult', 'digit', 'disappoint', 'display', 'durabl', 'easi', 'easili', 'eleg', 'end', 'everi', 'everyday', 'everyth', 'exact', 'excel', 'expect', 'expens', 'face', 'far', 'fast', 'favorit', 'featur', 'feel', 'fell', 'figur', 'fine', 'fit', 'function', 'gave', 'gift', 'glass', 'goe', 'gold', 'good', 'got', 'great', 'hand', 'happi', 'hard', 'heavi', 'help', 'high', 'hold', 'hope', 'hour', 'howev', 'husband', 'instruct', 'invicta', 'issu', 'item', 'know', 'larg', 'larger', 'leather', 'light', 'like', 'link', 'littl', 'long', 'look', 'lot', 'love', 'make', 'mani', 'metal', 'minut', 'model', 'money', 'month', 'movement', 'need', 'new', 'nice', 'night', 'notic', 'number', 'ok', 'old', 'open', 'order', 'origin', 'overal', 'packag', 'pay', 'peopl', 'perfect', 'person', 'pictur', 'piec', 'pin', 'plastic', 'pleas', 'pretti', 'price', 'probabl', 'problem', 'product', 'purchas', 'qualiti', 'quick', 'quit', 'read', 'real', 'realli', 'reason', 'receiv', 'recommend', 'remov', 'replac', 'resist', 'return', 'review', 'right', 'run', 'said', 'say', 'scratch', 'second', 'seiko', 'seller', 'set', 'sever', 'ship', 'simpl', 'sinc', 'size', 'small', 'smaller', 'solid', 'someth', 'son', 'star', 'start', 'stop', 'strap', 'style', 'stylish', 'super', 'sure', 'tell', 'thank', 'thing', 'think', 'thought', 'time', 'timex', 'took', 'tri', 'turn', 'use', 'valu', 'want', 'watch', 'water', 'way', 'wear', 'week', 'weight', 'white', 'wife', 'wish', 'work', 'worn', 'worth', 'wrist', 'year']\n"
     ]
    }
   ],
   "source": [
    "# Save terms identified by TF-IDF\n",
    "tf_selected_words = tfidf_model.get_feature_names()\n",
    "print(tf_selected_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# define number of clusters\n",
    "num_clusters = 5\n",
    "km = KMeans(n_clusters= num_clusters)\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely love this watch! Get compliments al...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love this watch it keeps time wonderfully.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scratches</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It works well on me. However, I found cheaper ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beautiful watch face.  The band looks nice all...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i love this watch for my purpose, about the pe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>for my wife and she loved it, looks great and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I was about to buy this thinking it was a Swis...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Watch is perfect. Rugged with the metal &amp;#34;B...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Great quality and build.&lt;br /&gt;The motors are r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  cluster\n",
       "0  Absolutely love this watch! Get compliments al...        4\n",
       "1       I love this watch it keeps time wonderfully.        1\n",
       "2                                          Scratches        4\n",
       "3  It works well on me. However, I found cheaper ...        4\n",
       "4  Beautiful watch face.  The band looks nice all...        4\n",
       "5  i love this watch for my purpose, about the pe...        4\n",
       "6  for my wife and she loved it, looks great and ...        2\n",
       "7  I was about to buy this thinking it was a Swis...        4\n",
       "8  Watch is perfect. Rugged with the metal &#34;B...        2\n",
       "9  Great quality and build.<br />The motors are r...        4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze K-means Result\n",
    "# Create dataframe films from all of the input files.\n",
    "product = {'review': df[:15000].review_body, 'cluster': clusters}\n",
    "frame = pd.DataFrame(product, columns = ['review', 'cluster'])\n",
    "frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster\n",
       "4    10587\n",
       "2     1569\n",
       "1     1022\n",
       "0      975\n",
       "3      847"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of reviews included in each cluster.\n",
    "frame['cluster'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.00499989, ..., 0.00340436, 0.00460536,\n",
       "        0.00128474],\n",
       "       [0.0004098 , 0.01794603, 0.00047436, ..., 0.        , 0.0049906 ,\n",
       "        0.00216037],\n",
       "       [0.00101928, 0.00412852, 0.00435933, ..., 0.00439511, 0.00812147,\n",
       "        0.01049133],\n",
       "       [0.        , 0.        , 0.00313669, ..., 0.00556213, 0.00751155,\n",
       "        0.00090661],\n",
       "       [0.00482522, 0.00620183, 0.00619551, ..., 0.00902359, 0.02522583,\n",
       "        0.01657956]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# km.cluster_centers_ denotes the importances of each items in centroid\n",
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 words:good,product,look,qualiti,price,recommend,\n",
      "Cluster 0 reviews (975 reviews): \n",
      "Cluster 1 words:love,gift,husband,beauti,wife,bought,\n",
      "Cluster 1 reviews (1022 reviews): \n",
      "Cluster 2 words:great,look,price,love,work,product,\n",
      "Cluster 2 reviews (1569 reviews): \n",
      "Cluster 3 words:nice,look,price,love,realli,like,\n",
      "Cluster 3 reviews (847 reviews): \n",
      "Cluster 4 words:look,like,time,band,work,love,\n",
      "Cluster 4 reviews (10587 reviews): \n"
     ]
    }
   ],
   "source": [
    "# Clustering result by K-means\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "cluster_keywords_summary = {}\n",
    "for i in range(num_clusters):\n",
    "    print (\"Cluster \" + str(i) + \" words:\", end='')\n",
    "    cluster_keywords_summary[i] = []\n",
    "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
    "        cluster_keywords_summary[i].append(tf_selected_words[ind])\n",
    "        print (tf_selected_words[ind] + \",\", end='')\n",
    "    print ()\n",
    "\n",
    "    cluster_reviews = frame[frame.cluster==i].review.tolist()\n",
    "    print (\"Cluster \" + str(i) + \" reviews (\" + str(len(cluster_reviews)) + \" reviews): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling - Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LDA for clustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75441685 0.0595699  0.06297061 0.06310917 0.05993348]\n",
      " [0.08436316 0.08412686 0.08735153 0.6569227  0.08723575]\n",
      " [0.10000078 0.10000088 0.59998525 0.1000009  0.10001218]\n",
      " ...\n",
      " [0.10018696 0.59968791 0.10011057 0.10000007 0.10001448]\n",
      " [0.08730112 0.08399738 0.08495703 0.65884727 0.0848972 ]\n",
      " [0.06800343 0.06847111 0.72205934 0.06916363 0.0723025 ]]\n"
     ]
    }
   ],
   "source": [
    "# document topic matrix for tfida_matrix_lda\n",
    "lda_output = lda.fit_transform(tfidf_matrix)\n",
    "print(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.5423918   25.84042365   0.2105005  ...   0.67426972  94.26972084\n",
      "   20.96506909]\n",
      " [  0.20180693   3.56771416   0.20141299 ...   9.91245663  91.09386261\n",
      "    1.21040106]\n",
      " [ 40.89954817   6.60404461  50.89000497 ...  43.03387802 110.65889129\n",
      "   91.86710687]\n",
      " [  0.20050495  54.85240854  22.43111231 ...   0.201233     0.53673661\n",
      "    0.2017021 ]\n",
      " [ 12.25840155   0.61268357   7.71510929 ...  57.63718758   0.20213397\n",
      "   82.97287656]]\n"
     ]
    }
   ],
   "source": [
    "# Topics and words matrix\n",
    "topic_word = lda.components_\n",
    "print(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc5</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc6</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc7</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc8</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc9</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic0  Topic1  Topic2  Topic3  Topic4  topic\n",
       "Doc0    0.75    0.06    0.06    0.06    0.06      0\n",
       "Doc1    0.08    0.08    0.09    0.66    0.09      3\n",
       "Doc2    0.10    0.10    0.60    0.10    0.10      2\n",
       "Doc3    0.06    0.06    0.74    0.07    0.07      2\n",
       "Doc4    0.15    0.04    0.73    0.04    0.04      2\n",
       "Doc5    0.70    0.07    0.07    0.07    0.07      0\n",
       "Doc6    0.07    0.06    0.06    0.74    0.06      3\n",
       "Doc7    0.06    0.06    0.75    0.06    0.07      2\n",
       "Doc8    0.33    0.05    0.53    0.05    0.05      2\n",
       "Doc9    0.06    0.07    0.76    0.06    0.06      2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_names = [\"Topic\" + str(i) for i in range(lda.n_components)]\n",
    "doc_names = ['Doc' + str(i) for i in range(len(data))]\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topic_names, index=doc_names)\n",
    "\n",
    "# get dominant topic for each document\n",
    "topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['topic'] = topic\n",
    "df_document_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic\n",
       "2   5105\n",
       "0   3389\n",
       "4   2537\n",
       "3   2194\n",
       "1   1775"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_topic['topic'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.5423918   25.84042365   0.2105005  ...   0.67426972  94.26972084\n",
      "   20.96506909]\n",
      " [  0.20180693   3.56771416   0.20141299 ...   9.91245663  91.09386261\n",
      "    1.21040106]\n",
      " [ 40.89954817   6.60404461  50.89000497 ...  43.03387802 110.65889129\n",
      "   91.86710687]\n",
      " [  0.20050495  54.85240854  22.43111231 ...   0.201233     0.53673661\n",
      "    0.2017021 ]\n",
      " [ 12.25840155   0.61268357   7.71510929 ...  57.63718758   0.20213397\n",
      "   82.97287656]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accur</th>\n",
       "      <th>actual</th>\n",
       "      <th>adjust</th>\n",
       "      <th>alarm</th>\n",
       "      <th>alreadi</th>\n",
       "      <th>alway</th>\n",
       "      <th>amaz</th>\n",
       "      <th>amazon</th>\n",
       "      <th>...</th>\n",
       "      <th>week</th>\n",
       "      <th>weight</th>\n",
       "      <th>white</th>\n",
       "      <th>wife</th>\n",
       "      <th>wish</th>\n",
       "      <th>work</th>\n",
       "      <th>worn</th>\n",
       "      <th>worth</th>\n",
       "      <th>wrist</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>0.542392</td>\n",
       "      <td>25.840424</td>\n",
       "      <td>0.210500</td>\n",
       "      <td>21.349630</td>\n",
       "      <td>21.327569</td>\n",
       "      <td>0.200346</td>\n",
       "      <td>2.778315</td>\n",
       "      <td>31.808451</td>\n",
       "      <td>0.201570</td>\n",
       "      <td>10.511356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201840</td>\n",
       "      <td>29.893737</td>\n",
       "      <td>4.987575</td>\n",
       "      <td>0.986931</td>\n",
       "      <td>15.382320</td>\n",
       "      <td>15.479009</td>\n",
       "      <td>9.994829</td>\n",
       "      <td>0.674270</td>\n",
       "      <td>94.269721</td>\n",
       "      <td>20.965069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>0.201807</td>\n",
       "      <td>3.567714</td>\n",
       "      <td>0.201413</td>\n",
       "      <td>0.218090</td>\n",
       "      <td>2.236834</td>\n",
       "      <td>0.200886</td>\n",
       "      <td>0.228981</td>\n",
       "      <td>0.292713</td>\n",
       "      <td>123.212693</td>\n",
       "      <td>2.381270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201249</td>\n",
       "      <td>0.208684</td>\n",
       "      <td>0.201973</td>\n",
       "      <td>0.200902</td>\n",
       "      <td>8.695506</td>\n",
       "      <td>47.665976</td>\n",
       "      <td>0.203069</td>\n",
       "      <td>9.912457</td>\n",
       "      <td>91.093863</td>\n",
       "      <td>1.210401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>40.899548</td>\n",
       "      <td>6.604045</td>\n",
       "      <td>50.890005</td>\n",
       "      <td>46.004562</td>\n",
       "      <td>70.804714</td>\n",
       "      <td>35.912878</td>\n",
       "      <td>52.138604</td>\n",
       "      <td>36.609637</td>\n",
       "      <td>0.306053</td>\n",
       "      <td>33.261173</td>\n",
       "      <td>...</td>\n",
       "      <td>109.793904</td>\n",
       "      <td>28.746361</td>\n",
       "      <td>47.905246</td>\n",
       "      <td>10.079687</td>\n",
       "      <td>39.345207</td>\n",
       "      <td>127.914272</td>\n",
       "      <td>46.565126</td>\n",
       "      <td>43.033878</td>\n",
       "      <td>110.658891</td>\n",
       "      <td>91.867107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>0.200505</td>\n",
       "      <td>54.852409</td>\n",
       "      <td>22.431112</td>\n",
       "      <td>0.201249</td>\n",
       "      <td>0.200886</td>\n",
       "      <td>0.201924</td>\n",
       "      <td>0.200658</td>\n",
       "      <td>0.201395</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.201077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200748</td>\n",
       "      <td>13.654278</td>\n",
       "      <td>0.201438</td>\n",
       "      <td>99.804981</td>\n",
       "      <td>5.008292</td>\n",
       "      <td>27.761517</td>\n",
       "      <td>0.201782</td>\n",
       "      <td>0.201233</td>\n",
       "      <td>0.536737</td>\n",
       "      <td>0.201702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>12.258402</td>\n",
       "      <td>0.612684</td>\n",
       "      <td>7.715109</td>\n",
       "      <td>4.547084</td>\n",
       "      <td>0.888337</td>\n",
       "      <td>21.851780</td>\n",
       "      <td>2.427890</td>\n",
       "      <td>13.151569</td>\n",
       "      <td>0.201320</td>\n",
       "      <td>51.207135</td>\n",
       "      <td>...</td>\n",
       "      <td>34.492387</td>\n",
       "      <td>0.200802</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>0.201590</td>\n",
       "      <td>5.641893</td>\n",
       "      <td>318.969858</td>\n",
       "      <td>4.486652</td>\n",
       "      <td>57.637188</td>\n",
       "      <td>0.202134</td>\n",
       "      <td>82.972877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              abl    absolut      accur     actual     adjust      alarm  \\\n",
       "Topic0   0.542392  25.840424   0.210500  21.349630  21.327569   0.200346   \n",
       "Topic1   0.201807   3.567714   0.201413   0.218090   2.236834   0.200886   \n",
       "Topic2  40.899548   6.604045  50.890005  46.004562  70.804714  35.912878   \n",
       "Topic3   0.200505  54.852409  22.431112   0.201249   0.200886   0.201924   \n",
       "Topic4  12.258402   0.612684   7.715109   4.547084   0.888337  21.851780   \n",
       "\n",
       "          alreadi      alway        amaz     amazon  ...        week  \\\n",
       "Topic0   2.778315  31.808451    0.201570  10.511356  ...    0.201840   \n",
       "Topic1   0.228981   0.292713  123.212693   2.381270  ...    0.201249   \n",
       "Topic2  52.138604  36.609637    0.306053  33.261173  ...  109.793904   \n",
       "Topic3   0.200658   0.201395    0.200698   0.201077  ...    0.200748   \n",
       "Topic4   2.427890  13.151569    0.201320  51.207135  ...   34.492387   \n",
       "\n",
       "           weight      white       wife       wish        work       worn  \\\n",
       "Topic0  29.893737   4.987575   0.986931  15.382320   15.479009   9.994829   \n",
       "Topic1   0.208684   0.201973   0.200902   8.695506   47.665976   0.203069   \n",
       "Topic2  28.746361  47.905246  10.079687  39.345207  127.914272  46.565126   \n",
       "Topic3  13.654278   0.201438  99.804981   5.008292   27.761517   0.201782   \n",
       "Topic4   0.200802   0.200820   0.201590   5.641893  318.969858   4.486652   \n",
       "\n",
       "            worth       wrist       year  \n",
       "Topic0   0.674270   94.269721  20.965069  \n",
       "Topic1   9.912457   91.093863   1.210401  \n",
       "Topic2  43.033878  110.658891  91.867107  \n",
       "Topic3   0.201233    0.536737   0.201702  \n",
       "Topic4  57.637188    0.202134  82.972877  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topic word matrix\n",
    "print(lda.components_)\n",
    "df_topic_words = pd.DataFrame(lda.components_)\n",
    "\n",
    "# column and index\n",
    "df_topic_words.columns = tfidf_model.get_feature_names()\n",
    "df_topic_words.index = topic_names\n",
    "df_topic_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>great</td>\n",
       "      <td>beauti</td>\n",
       "      <td>look</td>\n",
       "      <td>love</td>\n",
       "      <td>awesom</td>\n",
       "      <td>big</td>\n",
       "      <td>compliment</td>\n",
       "      <td>husband</td>\n",
       "      <td>like</td>\n",
       "      <td>pictur</td>\n",
       "      <td>lot</td>\n",
       "      <td>wrist</td>\n",
       "      <td>watch</td>\n",
       "      <td>bought</td>\n",
       "      <td>happi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>perfect</td>\n",
       "      <td>qualiti</td>\n",
       "      <td>fit</td>\n",
       "      <td>band</td>\n",
       "      <td>recommend</td>\n",
       "      <td>amaz</td>\n",
       "      <td>small</td>\n",
       "      <td>cute</td>\n",
       "      <td>ok</td>\n",
       "      <td>great</td>\n",
       "      <td>look</td>\n",
       "      <td>high</td>\n",
       "      <td>good</td>\n",
       "      <td>eleg</td>\n",
       "      <td>wrist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>nice</td>\n",
       "      <td>time</td>\n",
       "      <td>band</td>\n",
       "      <td>look</td>\n",
       "      <td>like</td>\n",
       "      <td>day</td>\n",
       "      <td>wear</td>\n",
       "      <td>use</td>\n",
       "      <td>cheap</td>\n",
       "      <td>strap</td>\n",
       "      <td>realli</td>\n",
       "      <td>face</td>\n",
       "      <td>hand</td>\n",
       "      <td>broke</td>\n",
       "      <td>read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>love</td>\n",
       "      <td>good</td>\n",
       "      <td>excel</td>\n",
       "      <td>price</td>\n",
       "      <td>gift</td>\n",
       "      <td>like</td>\n",
       "      <td>great</td>\n",
       "      <td>look</td>\n",
       "      <td>wife</td>\n",
       "      <td>pretti</td>\n",
       "      <td>nice</td>\n",
       "      <td>stylish</td>\n",
       "      <td>easi</td>\n",
       "      <td>simpl</td>\n",
       "      <td>durabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>work</td>\n",
       "      <td>product</td>\n",
       "      <td>thank</td>\n",
       "      <td>great</td>\n",
       "      <td>batteri</td>\n",
       "      <td>expect</td>\n",
       "      <td>time</td>\n",
       "      <td>arriv</td>\n",
       "      <td>item</td>\n",
       "      <td>fast</td>\n",
       "      <td>cool</td>\n",
       "      <td>ship</td>\n",
       "      <td>money</td>\n",
       "      <td>best</td>\n",
       "      <td>valu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word 0   Word 1 Word 2 Word 3     Word 4  Word 5      Word 6  \\\n",
       "Topic 0    great   beauti   look   love     awesom     big  compliment   \n",
       "Topic 1  perfect  qualiti    fit   band  recommend    amaz       small   \n",
       "Topic 2     nice     time   band   look       like     day        wear   \n",
       "Topic 3     love     good  excel  price       gift    like       great   \n",
       "Topic 4     work  product  thank  great    batteri  expect        time   \n",
       "\n",
       "          Word 7 Word 8  Word 9 Word 10  Word 11 Word 12 Word 13 Word 14  \n",
       "Topic 0  husband   like  pictur     lot    wrist   watch  bought   happi  \n",
       "Topic 1     cute     ok   great    look     high    good    eleg   wrist  \n",
       "Topic 2      use  cheap   strap  realli     face    hand   broke    read  \n",
       "Topic 3     look   wife  pretti    nice  stylish    easi   simpl  durabl  \n",
       "Topic 4    arriv   item    fast    cool     ship   money    best    valu  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print top n keywords for each topic\n",
    "def print_topic_words(tfidf_model, lda_model, n_words):\n",
    "    words = np.array(tfidf_model.get_feature_names())\n",
    "    topic_words = []\n",
    "    # for each topic, we have words weight\n",
    "    for topic_words_weights in lda_model.components_:\n",
    "        top_words = topic_words_weights.argsort()[::-1][:n_words]\n",
    "        topic_words.append(words.take(top_words))\n",
    "    return topic_words\n",
    "\n",
    "topic_keywords = print_topic_words(tfidf_model=tfidf_model, lda_model=lda, n_words=15)        \n",
    "\n",
    "df_topic_words = pd.DataFrame(topic_keywords)\n",
    "df_topic_words.columns = ['Word '+str(i) for i in range(df_topic_words.shape[1])]\n",
    "df_topic_words.index = ['Topic '+str(i) for i in range(df_topic_words.shape[0])]\n",
    "df_topic_words"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
